{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Licensed to the Apache Software Foundation (ASF) under one\n",
    "or more contributor license agreements.  See the NOTICE file\n",
    "distributed with this work for additional information\n",
    "regarding copyright ownership.  The ASF licenses this file\n",
    "to you under the Apache License, Version 2.0 (the\n",
    "\"License\"); you may not use this file except in compliance\n",
    "with the License.  You may obtain a copy of the License at\n",
    "  http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing,\n",
    "software distributed under the License is distributed on an\n",
    "\"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "KIND, either express or implied.  See the License for the\n",
    "specific language governing permissions and limitations\n",
    "under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr, when, explode\n",
    "\n",
    "\n",
    "\n",
    "from sedona.spark import *\n",
    "from utilities import getConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Sedona environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/18 22:38:41 WARN Utils: Your hostname, Nileshs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.24.19.124 instead (on interface en0)\n",
      "23/10/18 22:38:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/nileshgajwani/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/nileshgajwani/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-shaded-3.0_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5d1ede8b-02f5-421d-a31c-93ed390d8872;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/nileshgajwani/Downloads/spark-3.4.1-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.sedona#sedona-spark-shaded-3.0_2.12;1.5.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.4.0-28.2 in central\n",
      ":: resolution report :: resolve 75ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.sedona#sedona-spark-shaded-3.0_2.12;1.5.0 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.4.0-28.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5d1ede8b-02f5-421d-a31c-93ed390d8872\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/2ms)\n",
      "23/10/18 22:38:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "config = SedonaContext.builder() .\\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-spark-shaded-3.0_2.12:1.5.0,'\n",
    "           'org.datasyslab:geotools-wrapper:1.4.0-28.2'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "sedona = SedonaContext.create(config)\n",
    "sc = sedona.sparkContext\n",
    "sc.setSystemProperty(\"sedona.global.charset\", \"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read countries shapefile into a Sedona DataFrame \n",
    "Data link: https://www.naturalearthdata.com/downloads/50m-cultural-vectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- featurecla: string (nullable = true)\n",
      " |-- scalerank: string (nullable = true)\n",
      " |-- LABELRANK: string (nullable = true)\n",
      " |-- SOVEREIGNT: string (nullable = true)\n",
      " |-- SOV_A3: string (nullable = true)\n",
      " |-- ADM0_DIF: string (nullable = true)\n",
      " |-- LEVEL: string (nullable = true)\n",
      " |-- TYPE: string (nullable = true)\n",
      " |-- ADMIN: string (nullable = true)\n",
      " |-- ADM0_A3: string (nullable = true)\n",
      " |-- GEOU_DIF: string (nullable = true)\n",
      " |-- GEOUNIT: string (nullable = true)\n",
      " |-- GU_A3: string (nullable = true)\n",
      " |-- SU_DIF: string (nullable = true)\n",
      " |-- SUBUNIT: string (nullable = true)\n",
      " |-- SU_A3: string (nullable = true)\n",
      " |-- BRK_DIFF: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- NAME_LONG: string (nullable = true)\n",
      " |-- BRK_A3: string (nullable = true)\n",
      " |-- BRK_NAME: string (nullable = true)\n",
      " |-- BRK_GROUP: string (nullable = true)\n",
      " |-- ABBREV: string (nullable = true)\n",
      " |-- POSTAL: string (nullable = true)\n",
      " |-- FORMAL_EN: string (nullable = true)\n",
      " |-- FORMAL_FR: string (nullable = true)\n",
      " |-- NAME_CIAWF: string (nullable = true)\n",
      " |-- NOTE_ADM0: string (nullable = true)\n",
      " |-- NOTE_BRK: string (nullable = true)\n",
      " |-- NAME_SORT: string (nullable = true)\n",
      " |-- NAME_ALT: string (nullable = true)\n",
      " |-- MAPCOLOR7: string (nullable = true)\n",
      " |-- MAPCOLOR8: string (nullable = true)\n",
      " |-- MAPCOLOR9: string (nullable = true)\n",
      " |-- MAPCOLOR13: string (nullable = true)\n",
      " |-- POP_EST: string (nullable = true)\n",
      " |-- POP_RANK: string (nullable = true)\n",
      " |-- GDP_MD_EST: string (nullable = true)\n",
      " |-- POP_YEAR: string (nullable = true)\n",
      " |-- LASTCENSUS: string (nullable = true)\n",
      " |-- GDP_YEAR: string (nullable = true)\n",
      " |-- ECONOMY: string (nullable = true)\n",
      " |-- INCOME_GRP: string (nullable = true)\n",
      " |-- WIKIPEDIA: string (nullable = true)\n",
      " |-- FIPS_10_: string (nullable = true)\n",
      " |-- ISO_A2: string (nullable = true)\n",
      " |-- ISO_A3: string (nullable = true)\n",
      " |-- ISO_A3_EH: string (nullable = true)\n",
      " |-- ISO_N3: string (nullable = true)\n",
      " |-- UN_A3: string (nullable = true)\n",
      " |-- WB_A2: string (nullable = true)\n",
      " |-- WB_A3: string (nullable = true)\n",
      " |-- WOE_ID: string (nullable = true)\n",
      " |-- WOE_ID_EH: string (nullable = true)\n",
      " |-- WOE_NOTE: string (nullable = true)\n",
      " |-- ADM0_A3_IS: string (nullable = true)\n",
      " |-- ADM0_A3_US: string (nullable = true)\n",
      " |-- ADM0_A3_UN: string (nullable = true)\n",
      " |-- ADM0_A3_WB: string (nullable = true)\n",
      " |-- CONTINENT: string (nullable = true)\n",
      " |-- REGION_UN: string (nullable = true)\n",
      " |-- SUBREGION: string (nullable = true)\n",
      " |-- REGION_WB: string (nullable = true)\n",
      " |-- NAME_LEN: string (nullable = true)\n",
      " |-- LONG_LEN: string (nullable = true)\n",
      " |-- ABBREV_LEN: string (nullable = true)\n",
      " |-- TINY: string (nullable = true)\n",
      " |-- HOMEPART: string (nullable = true)\n",
      " |-- MIN_ZOOM: string (nullable = true)\n",
      " |-- MIN_LABEL: string (nullable = true)\n",
      " |-- MAX_LABEL: string (nullable = true)\n",
      " |-- NE_ID: string (nullable = true)\n",
      " |-- WIKIDATAID: string (nullable = true)\n",
      " |-- NAME_AR: string (nullable = true)\n",
      " |-- NAME_BN: string (nullable = true)\n",
      " |-- NAME_DE: string (nullable = true)\n",
      " |-- NAME_EN: string (nullable = true)\n",
      " |-- NAME_ES: string (nullable = true)\n",
      " |-- NAME_FR: string (nullable = true)\n",
      " |-- NAME_EL: string (nullable = true)\n",
      " |-- NAME_HI: string (nullable = true)\n",
      " |-- NAME_HU: string (nullable = true)\n",
      " |-- NAME_ID: string (nullable = true)\n",
      " |-- NAME_IT: string (nullable = true)\n",
      " |-- NAME_JA: string (nullable = true)\n",
      " |-- NAME_KO: string (nullable = true)\n",
      " |-- NAME_NL: string (nullable = true)\n",
      " |-- NAME_PL: string (nullable = true)\n",
      " |-- NAME_PT: string (nullable = true)\n",
      " |-- NAME_RU: string (nullable = true)\n",
      " |-- NAME_SV: string (nullable = true)\n",
      " |-- NAME_TR: string (nullable = true)\n",
      " |-- NAME_VI: string (nullable = true)\n",
      " |-- NAME_ZH: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/18 22:38:45 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "countries = ShapefileReader.readToGeometryRDD(sc, \"data/ne_50m_admin_0_countries_lakes/\")\n",
    "countries_df = Adapter.toDf(countries, sedona)\n",
    "countries_df.createOrReplaceTempView(\"country\")\n",
    "countries_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read airports shapefile into a Sedona DataFrame \n",
    "Data link: https://www.naturalearthdata.com/downloads/50m-cultural-vectors/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- scalerank: string (nullable = true)\n",
      " |-- featurecla: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- abbrev: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- wikipedia: string (nullable = true)\n",
      " |-- natlscale: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports = ShapefileReader.readToGeometryRDD(sc, \"data/ne_50m_airports/\")\n",
    "airports_df = Adapter.toDf(airports, sedona)\n",
    "airports_df.createOrReplaceTempView(\"airport\")\n",
    "airports_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Spatial Join using SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sedona.sql(\"SELECT c.geometry as country_geom, c.NAME_EN, a.geometry as airport_geom, a.name FROM country c, airport a WHERE ST_Contains(c.geometry, a.geometry)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Spatial Join using RDD API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3.0', '2.12', '1.5.0')]\n"
     ]
    }
   ],
   "source": [
    "airports_rdd = Adapter.toSpatialRdd(airports_df, \"geometry\")\n",
    "# Drop the duplicate name column in countries_df\n",
    "countries_df = countries_df.drop(\"NAME\")\n",
    "countries_rdd = Adapter.toSpatialRdd(countries_df, \"geometry\")\n",
    "\n",
    "airports_rdd.analyze()\n",
    "countries_rdd.analyze()\n",
    "\n",
    "# 4 is the num partitions used in spatial partitioning. This is an optional parameter\n",
    "airports_rdd.spatialPartitioning(GridType.KDBTREE, 4)\n",
    "countries_rdd.spatialPartitioning(airports_rdd.getPartitioner())\n",
    "\n",
    "buildOnSpatialPartitionedRDD = True\n",
    "usingIndex = True\n",
    "considerBoundaryIntersection = True\n",
    "airports_rdd.buildIndex(IndexType.QUADTREE, buildOnSpatialPartitionedRDD)\n",
    "\n",
    "result_pair_rdd = JoinQueryRaw.SpatialJoinQueryFlat(airports_rdd, countries_rdd, usingIndex, considerBoundaryIntersection)\n",
    "\n",
    "result2 = Adapter.toDf(result_pair_rdd, countries_rdd.fieldNames, airports.fieldNames, sedona)\n",
    "\n",
    "result2.createOrReplaceTempView(\"join_result_with_all_cols\")\n",
    "# Select the columns needed in the join\n",
    "result2 = sedona.sql(\"SELECT leftgeometry as country_geom, NAME_EN, rightgeometry as airport_geom, name FROM join_result_with_all_cols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print spatial join results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/18 22:38:46 WARN JoinQuery: UseIndex is true, but no index exists. Will build index on the fly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|        country_geom|             NAME_EN|        airport_geom|                name|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|MULTIPOLYGON (((1...|Taiwan           ...|POINT (121.231370...|Taoyuan          ...|\n",
      "|MULTIPOLYGON (((5...|Netherlands      ...|POINT (4.76437693...|Schiphol         ...|\n",
      "|POLYGON ((103.969...|Singapore        ...|POINT (103.986413...|Singapore Changi ...|\n",
      "|MULTIPOLYGON (((-...|United Kingdom   ...|POINT (-0.4531566...|London Heathrow  ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-149.98172...|Anchorage Int'l  ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-84.425397...|Hartsfield-Jackso...|\n",
      "|MULTIPOLYGON (((1...|People's Republic...|POINT (116.588174...|Beijing Capital  ...|\n",
      "|MULTIPOLYGON (((-...|Colombia         ...|POINT (-74.143371...|Eldorado Int'l   ...|\n",
      "|MULTIPOLYGON (((6...|India            ...|POINT (72.8745639...|Chhatrapati Shiva...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-71.016406...|Gen E L Logan Int...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-76.668642...|Baltimore-Washing...|\n",
      "|POLYGON ((36.8713...|Egypt            ...|POINT (31.3997430...|Cairo Int'l      ...|\n",
      "|POLYGON ((-2.2196...|Morocco          ...|POINT (-7.6632188...|Casablanca-Anfa  ...|\n",
      "|MULTIPOLYGON (((-...|Venezuela        ...|POINT (-67.005748...|Simon Bolivar Int...|\n",
      "|MULTIPOLYGON (((2...|South Africa     ...|POINT (18.5976565...|Cape Town Int'l  ...|\n",
      "|MULTIPOLYGON (((1...|People's Republic...|POINT (103.956136...|Chengdushuang Liu...|\n",
      "|MULTIPOLYGON (((6...|India            ...|POINT (77.0878362...|Indira Gandhi Int...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-104.67379...|Denver Int'l     ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-97.040371...|Dallas-Ft. Worth ...|\n",
      "|MULTIPOLYGON (((1...|Thailand         ...|POINT (100.602578...|Don Muang Int'l  ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|        country_geom|             NAME_EN|        airport_geom|                name|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-80.145258...|Fort Lauderdale H...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-80.278971...|Miami Int'l      ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-95.333704...|George Bush Inter...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-90.256693...|New Orleans Int'l...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-81.307371...|Orlando Int'l    ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-82.534824...|Tampa Int'l      ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-112.01363...|Sky Harbor Int'l ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-118.40246...|Los Angeles Int'l...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-116.97547...|General Abelardo ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-97.040371...|Dallas-Ft. Worth ...|\n",
      "|MULTIPOLYGON (((-...|United States of ...|POINT (-84.425397...|Hartsfield-Jackso...|\n",
      "|POLYGON ((-69.965...|Peru             ...|POINT (-77.107565...|Jorge Chavez     ...|\n",
      "|MULTIPOLYGON (((-...|Panama           ...|POINT (-79.387134...|Tocumen Int'l    ...|\n",
      "|POLYGON ((-83.157...|Nicaragua        ...|POINT (-86.171284...|Augusto Cesar San...|\n",
      "|MULTIPOLYGON (((-...|Mexico           ...|POINT (-96.183570...|Gen. Heriberto Ja...|\n",
      "|MULTIPOLYGON (((-...|Mexico           ...|POINT (-106.27001...|General Rafael Bu...|\n",
      "|MULTIPOLYGON (((-...|Mexico           ...|POINT (-99.754508...|General Juan N Al...|\n",
      "|MULTIPOLYGON (((-...|Mexico           ...|POINT (-99.570649...|Jose Maria Morelo...|\n",
      "|MULTIPOLYGON (((-...|Mexico           ...|POINT (-98.375759...|Puebla           ...|\n",
      "|MULTIPOLYGON (((-...|Mexico           ...|POINT (-99.082607...|Lic Benito Juarez...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The result of SQL API\n",
    "result.show()\n",
    "# The result of RDD API\n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group airports by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+\n",
      "|             NAME_EN|        country_geom|AirportCount|\n",
      "+--------------------+--------------------+------------+\n",
      "|Cuba             ...|MULTIPOLYGON (((-...|           1|\n",
      "|Mexico           ...|MULTIPOLYGON (((-...|          12|\n",
      "|Panama           ...|MULTIPOLYGON (((-...|           1|\n",
      "|Nicaragua        ...|POLYGON ((-83.157...|           1|\n",
      "|Honduras         ...|MULTIPOLYGON (((-...|           1|\n",
      "|Colombia         ...|MULTIPOLYGON (((-...|           4|\n",
      "|United States of ...|MULTIPOLYGON (((-...|          35|\n",
      "|Ecuador          ...|MULTIPOLYGON (((-...|           1|\n",
      "|The Bahamas      ...|MULTIPOLYGON (((-...|           1|\n",
      "|Peru             ...|POLYGON ((-69.965...|           1|\n",
      "|Guatemala        ...|POLYGON ((-92.235...|           1|\n",
      "|Canada           ...|MULTIPOLYGON (((-...|          15|\n",
      "|Venezuela        ...|MULTIPOLYGON (((-...|           3|\n",
      "|Argentina        ...|MULTIPOLYGON (((-...|           3|\n",
      "|Bolivia          ...|MULTIPOLYGON (((-...|           2|\n",
      "|Paraguay         ...|POLYGON ((-58.159...|           1|\n",
      "|Benin            ...|POLYGON ((1.62265...|           1|\n",
      "|Guinea           ...|POLYGON ((-10.283...|           1|\n",
      "|Chile            ...|MULTIPOLYGON (((-...|           5|\n",
      "|Nigeria          ...|MULTIPOLYGON (((7...|           3|\n",
      "+--------------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# result.createOrReplaceTempView(\"result\")\n",
    "result2.createOrReplaceTempView(\"result\")\n",
    "groupedresult = sedona.sql(\"SELECT c.NAME_EN, c.country_geom, count(*) as AirportCount FROM result c GROUP BY c.NAME_EN, c.country_geom\")\n",
    "groupedresult.show()\n",
    "groupedresult.createOrReplaceTempView(\"grouped_result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the number of airports in each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sedona_kepler_map = SedonaKepler.create_map(df=groupedresult, name=\"AirportCount\", config=getConfig())\n",
    "# sedona_kepler_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|             NAME_EN|        country_geom|           s2_cellID|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Cuba             ...|MULTIPOLYGON (((-...|[-859286808902290...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "root\n",
      " |-- NAME_EN: string (nullable = true)\n",
      " |-- country_geom: geometry (nullable = true)\n",
      " |-- s2_cellID: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h3_df = sedona.sql(\"SELECT g.NAME_EN, g.country_geom, ST_S2CellIDs(g.country_geom, 3) as s2_cellID from grouped_result g\")#groupedresult.selectExpr(\"ST_H3CellIDs(country_geom, 3, true) as h3_cellId\")\n",
    "h3_df.show(1)\n",
    "h3_df.printSchema()\n",
    "h3_df.createOrReplaceTempView(\"grouped_s2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAME_EN: string (nullable = true)\n",
      " |-- country_geom: geometry (nullable = true)\n",
      " |-- exploded_cellIds: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|             NAME_EN|        country_geom|    exploded_cellIds|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Cuba             ...|MULTIPOLYGON (((-...|-8592868089022906368|\n",
      "|Cuba             ...|MULTIPOLYGON (((-...|-8556839292003942400|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df = h3_df.select(h3_df.NAME_EN, h3_df.country_geom, explode(h3_df.s2_cellID).alias(\"exploded_cellIds\"))\n",
    "exploded_df.printSchema()\n",
    "exploded_df.show(2)\n",
    "exploded_df.createOrReplaceTempView(\"exploded_cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|             NAME_EN|        country_geom|                  s2|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Cuba             ...|MULTIPOLYGON (((-...|-8592868089022906368|\n",
      "|Mexico           ...|MULTIPOLYGON (((-...|-8592868089022906368|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- NAME_EN: string (nullable = true)\n",
      " |-- country_geom: geometry (nullable = true)\n",
      " |-- s2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_s2 = sedona.sql(\"SELECT s.NAME_EN, s.country_geom, exploded_cellIds as s2 FROM (grouped_s2 s CROSS JOIN exploded_cells e)\")\n",
    "df_s2.show(2)\n",
    "df_s2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/18 22:38:53 ERROR Executor: Exception in task 0.0 in stage 58.0 (TID 72)1]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\n",
      "\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$2719/0x000000080131a840.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:185)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:164)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:237)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:49)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:38)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:86)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)\n",
      "\tat com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:274)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:599)\n",
      "23/10/18 22:38:53 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 58.0 (TID 72),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\n",
      "\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$2719/0x000000080131a840.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:185)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:164)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:237)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:49)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:38)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:86)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)\n",
      "\tat com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:274)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:599)\n",
      "23/10/18 22:38:53 WARN TaskSetManager: Lost task 0.0 in stage 58.0 (TID 72) (172.24.19.124 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.nio.HeapByteBuffer.<init>(HeapByteBuffer.java:61)\n",
      "\tat java.base/java.nio.ByteBuffer.allocate(ByteBuffer.java:348)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.$anonfun$serializeToChunkedBuffer$1$adapted(SerializerHelper.scala:40)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$$$Lambda$2719/0x000000080131a840.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.allocateNewChunkIfNeeded(ChunkedByteBufferOutputStream.scala:87)\n",
      "\tat org.apache.spark.util.io.ChunkedByteBufferOutputStream.write(ChunkedByteBufferOutputStream.scala:75)\n",
      "\tat com.esotericsoftware.kryo.io.Output.flush(Output.java:185)\n",
      "\tat com.esotericsoftware.kryo.io.Output.require(Output.java:164)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:251)\n",
      "\tat com.esotericsoftware.kryo.io.Output.writeBytes(Output.java:237)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:49)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ByteArraySerializer.write(DefaultArraySerializers.java:38)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:629)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:86)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575)\n",
      "\tat com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79)\n",
      "\tat com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:37)\n",
      "\tat com.twitter.chill.Tuple2Serializer.write(TupleSerializers.scala:33)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\n",
      "\tat com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\n",
      "\tat com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\n",
      "\tat org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:274)\n",
      "\tat org.apache.spark.serializer.SerializerHelper$.serializeToChunkedBuffer(SerializerHelper.scala:42)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:599)\n",
      "\n",
      "23/10/18 22:38:53 ERROR TaskSetManager: Task 0 in stage 58.0 failed 1 times; aborting job\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nileshgajwani/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nileshgajwani/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/nileshgajwani/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nileshgajwani/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [Errno 54] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nileshgajwani/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/nileshgajwani/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/spark-3.4.1-bin-hadoop3/python/pyspark/sql/dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/Downloads/spark-3.4.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o87.collectToPython",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sedona_kepler_map_s2 \u001b[38;5;241m=\u001b[39m \u001b[43mSedonaKepler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAirportCount\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgetConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sedona_kepler_map_s2\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/sedona/maps/SedonaKepler.py:35\u001b[0m, in \u001b[0;36mSedonaKepler.create_map\u001b[0;34m(cls, df, name, config)\u001b[0m\n\u001b[1;32m     33\u001b[0m kepler_map \u001b[38;5;241m=\u001b[39m KeplerGl()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mSedonaKepler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkepler_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     kepler_map\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/sedona/maps/SedonaKepler.py:51\u001b[0m, in \u001b[0;36mSedonaKepler.add_df\u001b[0;34m(cls, kepler_map, df, name)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_df\u001b[39m(\u001b[38;5;28mcls\u001b[39m, kepler_map, df, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munnamed\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Adds a SedonaDataFrame to a given map object.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    :param kepler_map: Map object to add SedonaDataFrame to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    :return: Does not return anything, adds df directly to the given map object\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     geo_df \u001b[38;5;241m=\u001b[39m \u001b[43mSedonaMapUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convert_to_gdf__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     kepler_map\u001b[38;5;241m.\u001b[39madd_data(geo_df, name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/sedona/maps/SedonaMapUtils.py:34\u001b[0m, in \u001b[0;36mSedonaMapUtils.__convert_to_gdf__\u001b[0;34m(cls, df, rename, geometry_col)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     geometry_col \u001b[38;5;241m=\u001b[39m SedonaMapUtils\u001b[38;5;241m.\u001b[39m__get_geometry_col__(df)\n\u001b[0;32m---> 34\u001b[0m pandas_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m geo_df \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(pandas_df, geometry\u001b[38;5;241m=\u001b[39mgeometry_col)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry_col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m rename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/spark-3.4.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py:208\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    209\u001b[0m column_counter \u001b[38;5;241m=\u001b[39m Counter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m    211\u001b[0m corrected_dtypes: List[Optional[Type]] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n",
      "File \u001b[0;32m~/Downloads/spark-3.4.1-bin-hadoop3/python/pyspark/sql/dataframe.py:1216\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \n\u001b[1;32m   1198\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1216\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mcollectToPython()\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/Downloads/spark-3.4.1-bin-hadoop3/python/pyspark/traceback_utils.py:81\u001b[0m, in \u001b[0;36mSCCallSiteSync.__exit__\u001b[0;34m(self, type, value, tb)\u001b[0m\n\u001b[1;32m     79\u001b[0m SCCallSiteSync\u001b[38;5;241m.\u001b[39m_spark_stack_depth \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SCCallSiteSync\u001b[38;5;241m.\u001b[39m_spark_stack_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetCallSite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/binder-Ql50YD1N/lib/python3.9/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket, server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_address\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_port\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket\u001b[38;5;241m.\u001b[39mmakefile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "source": [
    "sedona_kepler_map_s2 = SedonaKepler.create_map(df=df_s2, name=\"AirportCount\", config=getConfig())\n",
    "sedona_kepler_map_s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "apache-sedona",
   "language": "python",
   "name": "apache-sedona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
